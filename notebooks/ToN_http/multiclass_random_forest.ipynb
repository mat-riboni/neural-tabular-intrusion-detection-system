{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc1fe05",
   "metadata": {},
   "source": [
    "# Multiclass classification on ToN http dataset with encoder clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77df2d2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "import os, sys\n",
    "import joblib\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..','..'))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)\n",
    "\n",
    "from src.utilities.config_manager import ConfigManager\n",
    "from src.utilities.io_handler import load_data\n",
    "from src.utilities.dataset_utils import *\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, f1_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2148f7",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7999ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CONFIG_PATH = '../../config/ton_config.json'\n",
    "\n",
    "ConfigManager.load_config(DATASET_CONFIG_PATH)\n",
    "paths_config = ConfigManager.get_section(\"paths\")\n",
    "data_cols_config = ConfigManager.get_section(\"data_columns\")\n",
    "\n",
    "DATA_PATH = '../../resources/dataset/http_ton.csv'\n",
    "OUTPUT_DIR = paths_config.get(\"output_dir\")\n",
    "TARGET_COL = data_cols_config.get(\"target_category_column\")\n",
    "NUMERICAL_COLS = data_cols_config.get(\"numerical_cols\")\n",
    "CATEGORICAL_COLS = data_cols_config.get(\"categorical_cols\")\n",
    "RANDOM_STATE = 42    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb679d",
   "metadata": {},
   "source": [
    "### Dataset loading and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e900a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(DATA_PATH)\n",
    "\n",
    "keep_cols = CATEGORICAL_COLS + NUMERICAL_COLS + [TARGET_COL]\n",
    "df = df[keep_cols].copy() \n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=RANDOM_STATE, stratify=df[TARGET_COL])\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=RANDOM_STATE, stratify=temp_df[TARGET_COL])   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bdded4",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "- StandardScaler per le features numeriche; nonostante TabNet accetti features numeriche raw, normalizzare i dati aumenta le performance del modello\n",
    "\n",
    "- LabelEncoder per le features categoriche; sarebbe meglio usare OrdinalEncoder, questo Ã¨ un esperimento. inoltre mappiamo le categorie sconosciute al train set con '_UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9634e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[NUMERICAL_COLS])\n",
    "for _df in (train_df, valid_df, test_df):\n",
    "    _df[NUMERICAL_COLS] = scaler.transform(_df[NUMERICAL_COLS])\n",
    "\n",
    "\n",
    "categorical_dims, encoders = {}, {}\n",
    "for col in CATEGORICAL_COLS:\n",
    "    le = LabelEncoder().fit(train_df[col])\n",
    "    le.classes_ = np.append(le.classes_, \"_UNK\")\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    valid_df[col] = le.transform(\n",
    "        valid_df[col].where(valid_df[col].isin(le.classes_), \"_UNK\")\n",
    "    )\n",
    "    test_df[col] = le.transform(\n",
    "        test_df[col].where(test_df[col].isin(le.classes_), \"_UNK\")\n",
    "    )\n",
    "    categorical_dims[col] = len(le.classes_)   \n",
    "    encoders[col] = le  \n",
    "y_le = LabelEncoder().fit(train_df[TARGET_COL])\n",
    "for _df in (train_df, valid_df, test_df):\n",
    "    _df[TARGET_COL] = y_le.transform(_df[TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9caf85",
   "metadata": {},
   "source": [
    "### Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79ff2951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used features: ['proto', 'conn_state', 'http_status_code', 'http_user_agent', 'http_method', 'duration', 'dst_bytes', 'missed_bytes', 'src_bytes', 'src_ip_bytes', 'src_pkts', 'dst_pkts', 'dst_ip_bytes', 'http_request_body_len', 'http_response_body_len']\n",
      "Unused features: ['type']\n"
     ]
    }
   ],
   "source": [
    "unused_feat = [ col for col in df.columns if col not in NUMERICAL_COLS + CATEGORICAL_COLS]\n",
    "\n",
    "features = [ col for col in df.columns if col not in unused_feat+[TARGET_COL]] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in CATEGORICAL_COLS]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in CATEGORICAL_COLS]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Used features: {features}\")\n",
    "print(f\"Unused features: {unused_feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b641329c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[features].values\n",
    "y_train = train_df[TARGET_COL].values\n",
    "\n",
    "X_valid = valid_df[features].values\n",
    "y_valid = valid_df[TARGET_COL].values\n",
    "\n",
    "X_test = test_df[features].values\n",
    "y_test = test_df[TARGET_COL].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f90b3",
   "metadata": {},
   "source": [
    "### Model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89dae51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mat/tesi_triennale/neural-tabular-intrusion-detection-system/venv/lib/python3.12/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced')\n",
    "rf.fit(X_train, y_train)\n",
    "preds = rf.predict(X_valid)\n",
    "print(balanced_accuracy_score(y_valid, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
