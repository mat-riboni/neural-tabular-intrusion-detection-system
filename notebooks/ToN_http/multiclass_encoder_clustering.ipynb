{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ffc1fe05",
   "metadata": {},
   "source": [
    "# Multiclass classification on ToN http dataset with encoder clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77df2d2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82b4fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import logging\n",
    "import os\n",
    "import joblib\n",
    "\n",
    "from src.utilities.config_manager import ConfigManager\n",
    "from src.utilities.io_handler import load_data\n",
    "from src.utilities.dataset_utils import *\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2148f7",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7999ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_CONFIG_PATH = './config/ton_config.json'\n",
    "\n",
    "ConfigManager.load_config(DATASET_CONFIG_PATH)\n",
    "paths_config = ConfigManager.get_section(\"paths\")\n",
    "data_cols_config = ConfigManager.get_section(\"data_columns\")\n",
    "\n",
    "DATA_PATH = paths_config.get(\"dataset_path\")\n",
    "OUTPUT_DIR = paths_config.get(\"output_dir\")\n",
    "TARGET_COL = data_cols_config.get(\"target_category_column\")\n",
    "NUMERICAL_COLS = data_cols_config.get(\"numerical_cols\")\n",
    "CATEGORICAL_COLS = data_cols_config.get(\"categorical_cols\")\n",
    "RANDOM_STATE = 42    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcb679d",
   "metadata": {},
   "source": [
    "### Dataset loading and splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e900a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data(DATA_PATH)\n",
    "\n",
    "keep_cols = CATEGORICAL_COLS + NUMERICAL_COLS + [TARGET_COL]\n",
    "df = df[keep_cols].copy() \n",
    "\n",
    "train_df, temp_df = train_test_split(df, test_size=0.3, random_state=RANDOM_STATE, stratify=df[TARGET_COL])\n",
    "valid_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=RANDOM_STATE, stratify=temp_df[TARGET_COL])   \n",
    "test_df.to_csv(f'./resources/dataset/test_set_ton.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bdded4",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "- StandardScaler per le features numeriche; nonostante TabNet accetti features numeriche raw, normalizzare i dati aumenta le performance del modello\n",
    "\n",
    "- LabelEncoder per le features categoriche; sarebbe meglio usare OrdinalEncoder, questo Ã¨ un esperimento. inoltre mappiamo le categorie sconosciute al train set con '_UNK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9634e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(train_df[NUMERICAL_COLS])\n",
    "for _df in (train_df, valid_df, test_df):\n",
    "    _df[NUMERICAL_COLS] = scaler.transform(_df[NUMERICAL_COLS])\n",
    "\n",
    "\n",
    "categorical_dims, encoders = {}, {}\n",
    "for col in CATEGORICAL_COLS:\n",
    "    le = LabelEncoder().fit(train_df[col])\n",
    "    le.classes_ = np.append(le.classes_, \"_UNK\")\n",
    "    train_df[col] = le.transform(train_df[col])\n",
    "    valid_df[col] = le.transform(\n",
    "        valid_df[col].where(valid_df[col].isin(le.classes_), \"_UNK\")\n",
    "    )\n",
    "    test_df[col] = le.transform(\n",
    "        test_df[col].where(test_df[col].isin(le.classes_), \"_UNK\")\n",
    "    )\n",
    "    categorical_dims[col] = len(le.classes_)   \n",
    "    encoders[col] = le  \n",
    "y_le = LabelEncoder().fit(train_df[TARGET_COL])\n",
    "for _df in (train_df, valid_df, test_df):\n",
    "    _df[TARGET_COL] = y_le.transform(_df[TARGET_COL])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b9caf85",
   "metadata": {},
   "source": [
    "### Some parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ff2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "unused_feat = [ col for col in df.columns if col not in NUMERICAL_COLS + CATEGORICAL_COLS]\n",
    "\n",
    "features = [ col for col in df.columns if col not in unused_feat+[TARGET_COL]] \n",
    "\n",
    "cat_idxs = [ i for i, f in enumerate(features) if f in CATEGORICAL_COLS]\n",
    "\n",
    "cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in CATEGORICAL_COLS]\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Used features: {features}\")\n",
    "print(f\"Unused features: {unused_feat}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "738f90b3",
   "metadata": {},
   "source": [
    "### Model instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89dae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TabNetClassifier(\n",
    "    n_d=64, n_a=64, n_steps=5,\n",
    "    gamma=1.8,\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=[min(50, (dim + 1) // 2) for dim in cat_dims], \n",
    "    lambda_sparse=1e-3,\n",
    "    momentum=0.02,\n",
    "    clip_value=1.5,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-2),  \n",
    "    scheduler_params={\"gamma\": 0.95, \"step_size\": 20},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    epsilon=1e-15, device_name=device\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef9b982",
   "metadata": {},
   "source": [
    "### Sets prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9843d752",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df[features].values\n",
    "y_train = train_df[TARGET_COL].values\n",
    "\n",
    "X_valid = valid_df[features].values\n",
    "y_valid = valid_df[TARGET_COL].values\n",
    "\n",
    "X_test = test_df[features].values\n",
    "y_test = test_df[TARGET_COL].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea50bf37",
   "metadata": {},
   "source": [
    "#### Computing class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c289b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "cw = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)\n",
    "cw = cw / cw.mean() # to avoid huge differences\n",
    "weights_tensor = torch.tensor(cw, dtype=torch.float).to(device)\n",
    "loss_fn = nn.CrossEntropyLoss(weight=weights_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2231e843",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1349c444",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "    eval_name=['train', 'valid'],\n",
    "    max_epochs=100, patience=15,\n",
    "    batch_size=2048, virtual_batch_size=256,\n",
    "    loss_fn=loss_fn,\n",
    "    eval_metric= ['balanced_accuracy', 'accuracy']\n",
    ")\n",
    "\n",
    "df_hist = pd.DataFrame(clf.history)\n",
    "ax = df_hist[[\n",
    "    'train_loss',\n",
    "    'train_balanced_accuracy'\n",
    "]].plot(figsize=(10, 5), grid=True)\n",
    "ax.set_xlabel('Epoch')\n",
    "ax.set_ylabel('Val')\n",
    "ax.set_title('Training vs Validation: Loss & Balanced Accuracy')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e67cd11",
   "metadata": {},
   "source": [
    "### Extracting encoder output\n",
    "\n",
    "Stiamo prendendo gli output di tutti gli step e li stiamo sommando, esattamente come fa tabnet, senza aggiungere l'utlimo layer lineare che serve a fare previsioni "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63d9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.network.eval()\n",
    "with torch.no_grad():\n",
    "    X_tensor = torch.tensor(X_test, device=clf.device, dtype=torch.float)\n",
    "    steps_output, _ = clf.network.encoder(X_tensor)\n",
    "    features = torch.sum(torch.stack(steps_output, dim=0), dim=0)  \n",
    "Z = features.cpu().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c004e35",
   "metadata": {},
   "source": [
    "### Dimension reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28ff695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "Z_2d = PCA(n_components=2, random_state=42).fit_transform(Z)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068d8bc9",
   "metadata": {},
   "source": [
    "### Clustering and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428126fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "labels = KMeans(n_clusters=3, random_state=42).fit_predict(Z_2d)\n",
    "plt.scatter(Z_2d[:,0], Z_2d[:,1], c=labels, alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37938b69",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2365ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "bal_acc = balanced_accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Test Accuracy: {acc:.4f}\")\n",
    "print(f\"Test Balanced Accuracy: {bal_acc:.4f}\")\n",
    "print(\"Classification Report:\\n\" + report)\n",
    "print(\"Confusion Matrix:\\n\" + str(cm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
